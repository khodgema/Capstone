{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E67lW6VhMKRj"
   },
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVezparJ8-bc",
    "outputId": "497c1e4a-4afa-4a2e-b627-3365e3f81b64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1051c3a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "\n",
    "\n",
    "#hyperparamiter tuning\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DvfzFuqwLofl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, pairwise_distances\n",
    "from sklearn import metrics\n",
    "#from google.colab import drive\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XVPQe-tL9ZB",
    "outputId": "760da110-7ea9-46e4-f3d1-a531d3c61770"
   },
   "source": [
    "#When using colab...\n",
    "drive.mount('/content/drive')\n",
    "data_path = '/content/drive/MyDrive/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MarPrlDQL-hG"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('2013-24_model_input_cluster_update_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_vg4QQqNHuO",
    "outputId": "2887d1b6-6755-401f-ab6b-450df1ce7fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SEASON_YEAR     TEAM_ID TEAM_ABBREVIATION_x      TEAM_NAME_x   GAME_ID  \\\n",
      "0         2013-14  1610612737                 ATL    Atlanta Hawks  21300023   \n",
      "20786     2013-14  1610612761                 TOR  Toronto Raptors  21300023   \n",
      "\n",
      "                 GAME_DATE      MATCHUP  WL  MIN_x  FGM  ...  cluster_1  \\\n",
      "0      2013-11-01T00:00:00  ATL vs. TOR   1   48.0   36  ...   0.041857   \n",
      "20786  2013-11-01T00:00:00    TOR @ ATL   0   48.0   40  ...   0.104286   \n",
      "\n",
      "       cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  \\\n",
      "0       0.023857   0.062714   0.047429        0.0        0.0   0.065286   \n",
      "20786   0.025429   0.042857   0.022571        0.0        0.0   0.024571   \n",
      "\n",
      "       cluster_8  cluster_9  cluster_10  \n",
      "0       0.014286   0.023857         0.0  \n",
      "20786   0.036857   0.011286         0.0  \n",
      "\n",
      "[2 rows x 109 columns]\n"
     ]
    }
   ],
   "source": [
    "specific_game_rows = df[df['GAME_ID'] == 21300023]\n",
    "\n",
    "print(specific_game_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKIm-u9lNVql",
    "outputId": "66d5dede-a9c8-43f8-9b32-c6de18dc6131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEASON_YEAR                0\n",
      "TEAM_ID                    0\n",
      "TEAM_ABBREVIATION_x        0\n",
      "TEAM_NAME_x                0\n",
      "GAME_ID                    0\n",
      "                          ..\n",
      "diff_PACE_PER40_rolling    0\n",
      "opp_POSS_rolling           0\n",
      "diff_POSS_rolling          0\n",
      "opp_PIE_rolling            0\n",
      "diff_PIE_rolling           0\n",
      "Length: 189, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rolling_stats = [col for col in df.columns if col.endswith('_rolling')]\n",
    "\n",
    "# create opponent columns and compute the difference for each rolling stat\n",
    "for stat in rolling_stats:\n",
    "    # Shift to get opponent's stats\n",
    "    df[f'opp_{stat}'] = df.groupby('GAME_ID')[stat].shift(-1)\n",
    "    df[f'diff_{stat}'] = df[stat] - df[f'opp_{stat}']\n",
    "\n",
    "# for the second team (reverse the shift), fill in the NaN values\n",
    "for stat in rolling_stats:\n",
    "    df[f'opp_{stat}'] = df.groupby('GAME_ID')[f'opp_{stat}'].fillna(df.groupby('GAME_ID')[stat].shift(1))\n",
    "    df[f'diff_{stat}'] = df[stat] - df[f'opp_{stat}']  # Difference between team's and opponent's rolling stats\n",
    "\n",
    "# NaN check\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4lOW-ITNixi"
   },
   "outputs": [],
   "source": [
    "## match up teams and create diff column\n",
    "# identify the rolling stats columns\n",
    "rolling_stats = [col for col in df.columns if col.endswith('_rolling')]\n",
    "\n",
    "cluster_cols = [col for col in df.columns if col.startswith('cluster_')]\n",
    "\n",
    "for stat in rolling_stats:\n",
    "    # Shift to get opponent's stats\n",
    "    df[f'opp_{stat}'] = df.groupby('GAME_ID')[stat].shift(-1)\n",
    "    df[f'diff_{stat}'] = df[stat] - df[f'opp_{stat}']\n",
    "\n",
    "for cluster in cluster_cols:\n",
    "    # Shift to get opponent's clusters\n",
    "    df[f'opp_{cluster}'] = df.groupby('GAME_ID')[cluster].shift(-1)\n",
    "    df[f'diff_{cluster}'] = df[cluster] - df[f'opp_{cluster}']\n",
    "\n",
    "for stat in rolling_stats:\n",
    "    df[f'opp_{stat}'] = df.groupby('GAME_ID')[f'opp_{stat}'].fillna(df.groupby('GAME_ID')[stat].shift(1))\n",
    "    df[f'diff_{stat}'] = df[stat] - df[f'opp_{stat}']  \n",
    "\n",
    "for cluster in cluster_cols:\n",
    "    df[f'opp_{cluster}'] = df.groupby('GAME_ID')[f'opp_{cluster}'].fillna(df.groupby('GAME_ID')[cluster].shift(1))\n",
    "    df[f'diff_{cluster}'] = df[cluster] - df[f'opp_{cluster}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nWqz3IXQfV8",
    "outputId": "e81cc19e-58e3-4bbe-e467-c819a2a9d7ec"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "zcDfDkjVQjom",
    "outputId": "c37d36cc-07cd-4db0-e5bd-4ccb9d44588f"
   },
   "outputs": [],
   "source": [
    "columns_to_keep = ['SEASON_YEAR', 'TEAM_ID', 'GAME_ID', 'WL', 'HOME_AWAY', 'win_percentage'] + \\\n",
    "                  [col for col in df.columns if (col.startswith('diff_') and col.endswith('_rolling')) or col.startswith('diff_cluster_')]\n",
    "df_model = df[columns_to_keep]\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWu1DiJzQ3Uh",
    "outputId": "04e59db9-2aed-41bf-8229-d27d3755d23c"
   },
   "outputs": [],
   "source": [
    "specific_game_rows = df_model[df_model['GAME_ID'] == 21300023]\n",
    "\n",
    "print(specific_game_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OLLxiBwYWhg",
    "outputId": "2193d1bc-1b1a-4755-9497-112c4405c76b"
   },
   "outputs": [],
   "source": [
    "list(df_model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQlq-jA-Q3R8",
    "outputId": "c2bebf20-28ed-4a6e-8e70-6fa425f70d1e"
   },
   "outputs": [],
   "source": [
    "len(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10CVUZFFaMOY",
    "outputId": "78f06bbf-320d-44b9-9e23-5c9f130afeab"
   },
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "columns_to_keep = [\n",
    "    'SEASON_YEAR',\n",
    "    'TEAM_ID',\n",
    "    'GAME_ID',\n",
    "    'WL',\n",
    "    'HOME_AWAY',\n",
    "    'win_percentage',\n",
    "    'diff_FGM_rolling',\n",
    "    'diff_FGA_rolling',\n",
    "    'diff_FG_PCT_rolling',\n",
    "    'diff_FG3M_rolling',\n",
    "    'diff_FG3A_rolling',\n",
    "    'diff_FG3_PCT_rolling',\n",
    "    'diff_FTM_rolling',\n",
    "    'diff_FTA_rolling',\n",
    "    'diff_FT_PCT_rolling',\n",
    "    'diff_OREB_rolling',\n",
    "    'diff_DREB_rolling',\n",
    "    'diff_REB_rolling',\n",
    "    'diff_AST_rolling',\n",
    "    'diff_TOV_rolling',\n",
    "    'diff_STL_rolling',\n",
    "    'diff_BLK_rolling',\n",
    "    'diff_BLKA_rolling',\n",
    "    'diff_PF_rolling',\n",
    "    'diff_PFD_rolling',\n",
    "    'diff_PTS_rolling',\n",
    "    'diff_PLUS_MINUS_rolling',\n",
    "    'diff_E_OFF_RATING_rolling',\n",
    "    'diff_OFF_RATING_rolling',\n",
    "    'diff_E_DEF_RATING_rolling',\n",
    "    'diff_DEF_RATING_rolling',\n",
    "    'diff_E_NET_RATING_rolling',\n",
    "    'diff_NET_RATING_rolling',\n",
    "    'diff_AST_PCT_rolling',\n",
    "    'diff_AST_TOV_rolling',\n",
    "    'diff_AST_RATIO_rolling',\n",
    "    'diff_E_TM_TOV_PCT_rolling',\n",
    "    'diff_TM_TOV_PCT_rolling',\n",
    "    'diff_EFG_PCT_rolling',\n",
    "    'diff_TS_PCT_rolling',\n",
    "    'diff_E_USG_PCT_rolling',\n",
    "    'diff_E_PACE_rolling',\n",
    "    'diff_PACE_rolling',\n",
    "    'diff_PACE_PER40_rolling',\n",
    "    'diff_POSS_rolling',\n",
    "    'diff_PIE_rolling',\n",
    "    'diff_cluster_0',\n",
    "    'diff_cluster_1',\n",
    "    'diff_cluster_2',\n",
    "    'diff_cluster_3',\n",
    "    'diff_cluster_4',\n",
    "    'diff_cluster_5',\n",
    "    'diff_cluster_6',\n",
    "    'diff_cluster_7',\n",
    "    'diff_cluster_8',\n",
    "    'diff_cluster_9',\n",
    "]\n",
    "\n",
    "df_model_cleaned = df_model[columns_to_keep]\n",
    "\n",
    "print(df_model_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fMfVW1kac3z",
    "outputId": "3459e71b-2514-427f-aa06-40e75ba2505b"
   },
   "outputs": [],
   "source": [
    "df_model_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxFGfitCRH7-"
   },
   "source": [
    "# Inferential Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O116QLGeQ3NG",
    "outputId": "9b23098a-411b-4a3e-9675-e18baf6e82a0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "y = df_model_cleaned[['WL']]\n",
    "X = df_model_cleaned.drop('WL',axis=1).select_dtypes(include=['float64', 'int64']).drop(['TEAM_ID','GAME_ID'],axis = 1)\n",
    "f_statistic, p_values = f_classif(X, y)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-Statistic': f_statistic,\n",
    "    'p-Value': p_values\n",
    "})\n",
    "results_df = results_df.sort_values(by='F-Statistic', ascending=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10), dpi=300)\n",
    "\n",
    "sns.barplot(x='F-Statistic', y='Feature', data=results_df, palette='viridis', ax=ax)\n",
    "ax.set_title('Feature Importance (F-Statistic)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x1dNVZSRT3G"
   },
   "source": [
    "# Training and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUQ5KVkHQ3Ki",
    "outputId": "91870346-5d3f-487f-ae32-82c068bf1e88"
   },
   "outputs": [],
   "source": [
    "null_counts = df_model_cleaned.isnull().sum()\n",
    "print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_NTq9v7KQ3H-",
    "outputId": "96061ee1-6dab-406a-cbb4-2d4566468212"
   },
   "outputs": [],
   "source": [
    "# final three seasons for the validation set\n",
    "df_val = df_model_cleaned[df_model_cleaned['SEASON_YEAR'].isin(['2021-22', '2022-23', '2023-24'])]\n",
    "\n",
    "# remaining seasons for training\n",
    "df_train_val = df_model_cleaned[~df_model_cleaned['SEASON_YEAR'].isin(['2021-22', '2022-23', '2023-24'])]\n",
    "\n",
    "X_train = df_train_val.drop(columns=['SEASON_YEAR', 'WL'])\n",
    "y_train = df_train_val['WL']\n",
    "\n",
    "X_val = df_val.drop(columns=['SEASON_YEAR', 'WL'])\n",
    "y_val = df_val['WL']\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "#print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Split\n",
    "X_train_val = df_model_cleaned.drop(columns=['SEASON_YEAR', 'WL'])\n",
    "y_train_val = df_model_cleaned['WL']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQKZSizTQ3FT"
   },
   "outputs": [],
   "source": [
    "X_train_identifiers = X_train[['TEAM_ID', 'GAME_ID']]\n",
    "X_val_identifiers = X_val[['TEAM_ID', 'GAME_ID']]\n",
    "#X_test_identifiers = X_test[['TEAM_ID', 'GAME_ID']]\n",
    "\n",
    "X_train = X_train.drop(columns=['TEAM_ID', 'GAME_ID'])\n",
    "X_val = X_val.drop(columns=['TEAM_ID', 'GAME_ID'])\n",
    "#X_test = X_test.drop(columns=['TEAM_ID', 'GAME_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-0v1cs5Q3Cg"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "#X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ZUXZAUGtQ2_0",
    "outputId": "5b80ed53-61b8-46fe-c380-140da4ec9d62"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(X_train_scaled_df['diff_PTS_rolling'], kde=True, color='blue')\n",
    "plt.title('Distribution of PTS_rolling Diff After Robust Scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "HnEvJFzWQ28y",
    "outputId": "ceafac6c-24be-4ede-a0ff-8bceb41e3ae3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(X_train_scaled_df['diff_OFF_RATING_rolling'], kde=True, color='blue')\n",
    "plt.title('Distribution of OFF_RATING_rolling diff After Robust Scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA4plHs3R-uY"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSndQgPISCG5"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jfd4JYuhyAh"
   },
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "#X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "C2eJ8lGFQ20X",
    "outputId": "03973ae8-990f-4f12-e001-a36727e4fac1"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_scaled_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_vls0oKQ2wz",
    "outputId": "71fabfe6-45f9-4000-bc4f-ddb9770af56a"
   },
   "outputs": [],
   "source": [
    "y_val_pred = log_reg.predict(X_val_scaled_df)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KWMYWbNSbeN"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7oiacZTRq7P",
    "outputId": "83925685-c9d1-400a-c110-449fc4962a3f"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# convert the dataset into DMatrix (optimized for XGBoost) -\n",
    "dtrain = xgb.DMatrix(X_train_scaled_df, label=y_train)\n",
    "dval = xgb.DMatrix(X_val_scaled_df, label=y_val)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.1,  # learning rate\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100, early_stopping_rounds=10, evals=evals)\n",
    "\n",
    "y_val_pred = (xgb_model.predict(dval) > 0.5).astype(int)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuxGynZBRq4l",
    "outputId": "a430d722-cf6a-4944-c8a3-0f90383d7d03"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [300],\n",
    "    'subsample': [0.7],\n",
    "    'colsample_bytree': [0.8]\n",
    "}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTxplkiS85vO"
   },
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cc1W4oMo8-Y5"
   },
   "outputs": [],
   "source": [
    "#prep data for for network\n",
    "#convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled_df.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val_scaled_df.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# combine into tensor dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Shuffle for training, No shuffle for testing\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hpGO0Ik88-WJ",
    "outputId": "2173c7d5-223b-4799-88a8-133e71ea402f"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# Define the main neural network model\n",
    "class WinLossNet(nn.Module):\n",
    "    def __init__(self,layer_sizes, drop_rate = 0.2284):\n",
    "        super(WinLossNet, self).__init__()\n",
    "\n",
    "        # main Layers\n",
    "        self.fc1 = nn.Linear(52, layer_sizes[0])\n",
    "        self.fc2 = nn.Linear(layer_sizes[0], layer_sizes[1])\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "        self.fc3 = nn.Linear(layer_sizes[1], layer_sizes[2])\n",
    "        self.fc4 = nn.Linear(layer_sizes[2], layer_sizes[3])\n",
    "        self.fc5 = nn.Linear(layer_sizes[3], 1)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # main\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, feed weights here to work with search function\n",
    "model = WinLossNet([512, 256, 128, 64])\n",
    "\n",
    "#send to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()   # Combines Sigmoid + BCELoss, feeds data through sigmoid function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.006774,weight_decay=0.0073022 )#1e-5)\n",
    "\n",
    "########even more kaden fun, let\n",
    "\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "learning_rates = []\n",
    "# knobs\n",
    "epochs = 20\n",
    "#scheduler = StepLR(optimizer, step_size=17, gamma=.95)  # Change learning rate over time, different options to test\n",
    "scheduler = ReduceLROnPlateau(optimizer,patience=6,factor=0.25983,cooldown=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()        # Training time\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)   #issue ******\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculte the trainging epocs stats\n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    epoch_train_acc = correct_preds / total_preds\n",
    "    train_loss_history.append(epoch_train_loss)\n",
    "    train_acc_history.append(epoch_train_acc)\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val_preds = 0\n",
    "    total_val_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val_preds += labels.size(0)\n",
    "            correct_val_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    #calculate validation stats\n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = correct_val_preds / total_val_preds\n",
    "    val_loss_history.append(epoch_val_loss)\n",
    "    val_acc_history.append(epoch_val_acc)\n",
    "\n",
    "    if epoch > 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], '\n",
    "              f'Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {epoch_train_acc:.4f},'\n",
    "              f'Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(epoch_val_loss)\n",
    "    #save chnages in learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        learning_rates.append(param_group['lr'])\n",
    "\n",
    "# Plot plot plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(1, epochs + 1), train_acc_history, label='Training Accuracy', marker='o')\n",
    "plt.plot(np.arange(1, epochs + 1), val_acc_history, label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Testing Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(learning_rates)\n",
    "plt.title('Learning Rate Over Epochs')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1X8qwyt8-TC"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "\n",
    "#to load model\n",
    "#model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKPNZHgI8-QJ",
    "outputId": "9640fbe2-71ec-4db4-f6fa-779b3f91313f"
   },
   "outputs": [],
   "source": [
    "# Define the objective function for hyperparameter search, close to hand tuning design above\n",
    "def objective(params):\n",
    "    batch_size = params['batch_size']\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = WinLossNet(layer_sizes=params['layer_sizes'],drop_rate=params['drop_rate']).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'],weight_decay=params['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=params['patience'], factor= params['factor'])\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(params['epochs']):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct, total,val_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'layer_sizes': hp.choice('layer_sizes', [\n",
    "        [256, 174, 96, 48],\n",
    "        [256, 128, 96, 32],\n",
    "        [256, 128, 64, 32],\n",
    "        [324, 256, 145, 64],\n",
    "        [512, 256, 128, 64],\n",
    "\n",
    "    ]),\n",
    "    'drop_rate': hp.uniform('drop_rate', 0.01, 0.7),\n",
    "    'lr': hp.loguniform('lr', -5, -1),\n",
    "    'epochs': hp.choice('epochs', [10,15, 20, 25,30]),\n",
    "    'patience': hp.choice('patience', [2,3,5,6,7,8,9]),\n",
    "    'factor' : hp.uniform('factor', 0.1,0.7),\n",
    "    'weight_decay' : hp.loguniform('weight_decay',-5,-1),\n",
    "    'batch_size' : hp.choice('batch_size', [16,32,64,128])\n",
    "}\n",
    "\n",
    "\n",
    "# Begin the hunt\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=400, trials=trials)\n",
    "\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4sUdBC68-NS"
   },
   "outputs": [],
   "source": [
    " model.eval()\n",
    "\n",
    "true_values = []\n",
    "predicted_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "        true_values.append(labels.cpu().numpy())\n",
    "        predicted_values.append(outputs.cpu().numpy())\n",
    "\n",
    "true_values = np.concatenate(true_values)\n",
    "predicted_values = np.concatenate(predicted_values)\n",
    "\n",
    "results_df = pd.DataFrame({'True_Values':true_values.flatten(),\n",
    "'pred_Values' : predicted_values.flatten()})\n",
    "results_df['pred_Values_B'] = (results_df['pred_Values'] > 0.5).astype(int)\n",
    "results_df = results_df.merge(X_val_identifiers.reset_index().drop('index',axis = 1), left_index=True, right_index=True)\n",
    "results_df = results_df.merge(X_val.reset_index().drop('index',axis = 1),left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uckNP1vb8-Kb"
   },
   "outputs": [],
   "source": [
    "results_df['correct_prediction'] = (results_df['True_Values'] == results_df['pred_Values_B']).astype(int)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4Sc0Yhw8-HC"
   },
   "outputs": [],
   "source": [
    "max(final_results['GAME_ID'].astype(str).str[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcUT5adw8-DL"
   },
   "outputs": [],
   "source": [
    "final_results = results_df.copy()\n",
    "final_results['season'] = final_results['GAME_ID'].astype(str).str[:3]  # First three digits for the season\n",
    "final_results['game_number'] = final_results['GAME_ID'].astype(str).str[-4:]  # Last three digits for the game number\n",
    "\n",
    "\n",
    "final_results['correct_prediction'] = (final_results['True_Values'] == final_results['pred_Values_B']).astype(int)\n",
    "final_results['incorrect_prediction'] = (final_results['True_Values'] != final_results['pred_Values_B']).astype(int)\n",
    "\n",
    "num_bins = 25\n",
    "bins = np.linspace(1, 1303, num_bins + 1) # 1303 = max number of games in a seasons\n",
    "final_results['game_number'] = final_results['game_number'].astype(int)\n",
    "final_results['binned_game_number'] = pd.cut(final_results['game_number'], bins=bins, include_lowest=True)\n",
    "\n",
    "binned_summary = final_results.groupby('binned_game_number').agg(\n",
    "    correct_predictions=('correct_prediction', 'sum'),\n",
    "    incorrect_predictions=('incorrect_prediction', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# make pretty plot\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(binned_summary))\n",
    "\n",
    "plt.bar(x - bar_width/2, binned_summary['correct_predictions'], width=bar_width, label='Correct Predictions', color='skyblue')\n",
    "plt.bar(x + bar_width/2, binned_summary['incorrect_predictions'], width=bar_width, label='Incorrect Predictions', color='salmon')\n",
    "\n",
    "plt.title('Predictions Throughout the Season (Binned)')\n",
    "plt.xlabel('Game Bins (one bin per week of regular season)')\n",
    "plt.ylabel('Predictions')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9ww13HmS455"
   },
   "source": [
    "## Playing with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkcxGmn-Rqwz"
   },
   "outputs": [],
   "source": [
    "# JS visualization for Jupyter\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_val_scaled_df)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_val_scaled_df.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZL0FmwoS8kT"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_val_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxpyv2eGTDNI"
   },
   "source": [
    "## Test: Model Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-5L88T3p7hg"
   },
   "outputs": [],
   "source": [
    "log_reg_pred_proba = log_reg.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "xgb_val_pred_proba = xgb_model.predict(dval) \n",
    "\n",
    "model.eval()\n",
    "nn_pred_proba = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader: \n",
    "        inputs = inputs.to(device)\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "        nn_pred_proba.extend(outputs.cpu().numpy()) \n",
    "nn_pred_proba = np.array(nn_pred_proba).flatten()\n",
    "\n",
    "blended_proba = (log_reg_pred_proba + xgb_val_pred_proba + nn_pred_proba) / 3\n",
    "\n",
    "blended_pred = (blended_proba >= 0.5).astype(int)\n",
    "\n",
    "blended_accuracy = accuracy_score(y_val, blended_pred)\n",
    "print(f\"Blended Validation Accuracy: {blended_accuracy:.4f}\")\n",
    "\n",
    "print(\"Blended Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, blended_pred))\n",
    "\n",
    "print(\"Blended Classification Report:\")\n",
    "print(classification_report(y_val, blended_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred_proba = log_reg.predict_proba(X_val_scaled_df)[:, 1]  \n",
    "log_reg_auc = roc_auc_score(y_val, log_reg_pred_proba)\n",
    "print(f\"Logistic Regression AUC: {log_reg_auc:.4f}\")\n",
    "\n",
    "xgb_val_pred_proba = xgb_model.predict(dval)  \n",
    "xgb_auc = roc_auc_score(y_val, xgb_val_pred_proba)\n",
    "print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
    "\n",
    "nn_pred_proba = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "        nn_pred_proba.extend(outputs.cpu().numpy())\n",
    "nn_pred_proba = np.array(nn_pred_proba).flatten()\n",
    "nn_auc = roc_auc_score(y_val, nn_pred_proba)\n",
    "print(f\"Neural Network AUC: {nn_auc:.4f}\")\n",
    "\n",
    "blended_proba = (log_reg_pred_proba + xgb_val_pred_proba + nn_pred_proba) / 3  # avg prob\n",
    "blended_auc = roc_auc_score(y_val, blended_proba)\n",
    "print(f\"Blended Model AUC: {blended_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_fpr, log_reg_tpr, _ = roc_curve(y_val, log_reg_pred_proba)\n",
    "log_reg_auc = auc(log_reg_fpr, log_reg_tpr)\n",
    "\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_val, xgb_val_pred_proba)\n",
    "xgb_auc = auc(xgb_fpr, xgb_tpr)\n",
    "\n",
    "nn_fpr, nn_tpr, _ = roc_curve(y_val, nn_pred_proba)\n",
    "nn_auc = auc(nn_fpr, nn_tpr)\n",
    "\n",
    "blended_fpr, blended_tpr, _ = roc_curve(y_val, blended_proba)\n",
    "blended_auc = auc(blended_fpr, blended_tpr)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axs[0, 0].plot(log_reg_fpr, log_reg_tpr, color='blue', label=f'Logistic Regression (AUC = {log_reg_auc:.4f})')\n",
    "axs[0, 0].plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.5)')\n",
    "axs[0, 0].set_title('Logistic Regression ROC Curve')\n",
    "axs[0, 0].set_xlabel('False Positive Rate')\n",
    "axs[0, 0].set_ylabel('True Positive Rate')\n",
    "axs[0, 0].legend(loc='lower right')\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "axs[0, 1].plot(xgb_fpr, xgb_tpr, color='green', label=f'XGBoost (AUC = {xgb_auc:.4f})')\n",
    "axs[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.5)')\n",
    "axs[0, 1].set_title('XGBoost ROC Curve')\n",
    "axs[0, 1].set_xlabel('False Positive Rate')\n",
    "axs[0, 1].set_ylabel('True Positive Rate')\n",
    "axs[0, 1].legend(loc='lower right')\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "axs[1, 0].plot(nn_fpr, nn_tpr, color='orange', label=f'Neural Network (AUC = {nn_auc:.4f})')\n",
    "axs[1, 0].plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.5)')\n",
    "axs[1, 0].set_title('Neural Network ROC Curve')\n",
    "axs[1, 0].set_xlabel('False Positive Rate')\n",
    "axs[1, 0].set_ylabel('True Positive Rate')\n",
    "axs[1, 0].legend(loc='lower right')\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "axs[1, 1].plot(blended_fpr, blended_tpr, color='red', label=f'Blended Model (AUC = {blended_auc:.4f})')\n",
    "axs[1, 1].plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.5)')\n",
    "axs[1, 1].set_title('Blended Model ROC Curve')\n",
    "axs[1, 1].set_xlabel('False Positive Rate')\n",
    "axs[1, 1].set_ylabel('True Positive Rate')\n",
    "axs[1, 1].legend(loc='lower right')\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_fpr, log_reg_tpr, _ = roc_curve(y_val, log_reg_pred_proba)\n",
    "log_reg_auc = auc(log_reg_fpr, log_reg_tpr)\n",
    "\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_val, xgb_val_pred_proba)\n",
    "xgb_auc = auc(xgb_fpr, xgb_tpr)\n",
    "\n",
    "nn_fpr, nn_tpr, _ = roc_curve(y_val, nn_pred_proba)\n",
    "nn_auc = auc(nn_fpr, nn_tpr)\n",
    "\n",
    "blended_fpr, blended_tpr, _ = roc_curve(y_val, blended_proba)\n",
    "blended_auc = auc(blended_fpr, blended_tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(log_reg_fpr, log_reg_tpr, label=f'Logistic Regression (AUC = {log_reg_auc:.4f})', color='blue')\n",
    "plt.plot(xgb_fpr, xgb_tpr, label=f'XGBoost (AUC = {xgb_auc:.4f})', color='green')\n",
    "plt.plot(nn_fpr, nn_tpr, label=f'Neural Network (AUC = {nn_auc:.4f})', color='orange')\n",
    "plt.plot(blended_fpr, blended_tpr, label=f'Blended Model (AUC = {blended_auc:.4f})', color='red')\n",
    "\n",
    "# 50% random guessing line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing (AUC = 0.5)')\n",
    "\n",
    "plt.title('ROC Curves for Models')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCNBtYf0qAEs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyrY1Ejyi15P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
